---
title: "CSP571 DPA FINAL PROJECT"
author : "Yash Pradeep Gupte - A20472798"
output: html_notebook
---


```{r}
#LOAD LIBRARIES
library(dplyr)
library(lubridate) 


library(ggplot2) 
library(hrbrthemes) 

library(tidyverse)
library(data.table) 

#time series
library(forecast)
library(tseries)
library(slider) 
library(TSstudio)  


#metrics
library(Metrics)
library(lmtest)
```



```{r}
#READ test data

nyc_test_data <- read.csv("test.csv")

```


```{r}
print(nyc_test_data)
```


```{r}
print(summary(nyc_test_data))
```

#LOAD 2M top(first) records from the entire train dataset:
```{r}
nyc_train_data <- read.csv("train.csv", nrows = 2000000)
```

```{r}
summary(nyc_train_data)
```

```{r}
print(nyc_train_data)
```

#------------------------------------------EDA-------------------------------------------------------------------------
Exploratory Data Analysis and Data Cleaning

```{r}
#MISSING VALUES IN TRAIN AND TEST
cat('Train data - number of missing vals:',sum(is.na(nyc_train_data)),"\n")
cat('Test data - number of missing vals:',sum(is.na(nyc_test_data)))
```

From the dataset summary we can see that Train data has missing or Nan values in 14 records combining the drop off latitute and dropoff longitude features. As there are 2 million records, dropping 14 records shouldn't be a problem 
```{r}
#DROPPING Nan Values records
nyc_train_data<- na.omit(nyc_train_data)

```

```{r}
cat('Train data - number of missing vals:',sum(is.na(nyc_train_data)),"\n")
```

#OBSERVE THE REPONSE - fare_amount
```{r}
summary(nyc_train_data$fare_amount)
```

There shouldn't be any negative values in fare amount, hence we should remove these records as well
```{r}
#nyc_train_data_1 = nyc_train_data[which(nyc_train_data$fare_amount < 0)]
#DROP NEGATIVE VALUES in fare_amount
nyc_train_data <- nyc_train_data[nyc_train_data$fare_amount>0, ]
```

```{r}
summary(nyc_train_data)
```

The max fare amount is $1273.31 which is vert high. We can set limit on the max fare amount like $500 and discard the rest of records
```{r}
nyc_train_data <- nyc_train_data[nyc_train_data$fare_amount<500, ]
```

```{r}
summary(nyc_train_data)
```

#CHECKING PASSENGER COUNT
We can observe that the  maximum passenger count  present in our dataset is 208 which seems unrealistic to be accomodated in a NYC Taxi. Assuming the TAXI is a SUV car , we can set our maximum passenger count to be 6 and discard the rest.

```{r}
nyc_train_data <- nyc_train_data[nyc_train_data$passenger_count<=6, ]
```


```{r}
summary(nyc_train_data$passenger_count)
```


#CHECK PICK UP AND DROP OFF LATITUDE AND LONGITUDE
Generally the range of latitude is between -90 to 90 degrees and that for longitude is -180 to 180 degrees
Hence we need to remove outliers present in the dataset.
```{r}
#PICKUP LATITUDE
nyc_train_data <- nyc_train_data[nyc_train_data$pickup_latitude <= 90, ]
nyc_train_data <- nyc_train_data[nyc_train_data$pickup_latitude >= -90, ]

#PICKUP LONGITUDE
nyc_train_data <- nyc_train_data[nyc_train_data$pickup_longitude <= 180, ]
nyc_train_data <- nyc_train_data[nyc_train_data$pickup_longitude >= -180, ]


#DROP OFF LATITUDE
nyc_train_data <- nyc_train_data[nyc_train_data$dropoff_latitude <= 90, ]
nyc_train_data <- nyc_train_data[nyc_train_data$dropoff_latitude >= -90, ]

#DROPOFF LONGITUDE
nyc_train_data <- nyc_train_data[nyc_train_data$dropoff_longitude <= 180, ]
nyc_train_data <- nyc_train_data[nyc_train_data$dropoff_longitude >= -180, ]
```


```{r}
summary(nyc_train_data)
```


#CHECK STRUCTURE OF ALL THE FEATURES / PREDICTORS 
```{r}
str(nyc_train_data)
```


```{r}
#EXPORT CLEANED DATA
#write.csv(nyc_train_data,"./train_data.csv", row.names = FALSE )
#write.csv(nyc_test_data,"./test_data.csv", row.names = FALSE )
```



```{r}
#IMPORT CLEANED DATA
nyc_train_data <- read.csv("./cleaned_data/train_data.csv")
nyc_test_data <- read.csv("./cleaned_data/test_data.csv")
```


#AS THE KEY AND PICKUP DATE TIME ARE IN CHARACTER FORMATS , WE NEED TO CHANGE IT TO DATETIME 
```{r}
#CONVERT CHAR TO DATETIME USING R package - lubridate()
nyc_train_data$key <- ymd_hms(nyc_train_data$key)
nyc_train_data$pickup_datetime <- ymd_hms(nyc_train_data$pickup_datetime)
```


```{r}
str(nyc_train_data)
print(nyc_train_data)
```



```{r}
#CONVERT CHAR TO DATETIME USING R package - lubridate()
nyc_test_data$key <- ymd_hms(nyc_test_data$key)
nyc_test_data$pickup_datetime <- ymd_hms(nyc_test_data$pickup_datetime)
```

#EDA to observe impact of predictors on response
#Q1. Does pick up date and time affect the fare?
#Q2. Does day of the week affect the fare?
#Q3. Does number of passengers affect the fare?

```{r}
#TRAIN DATA - date-time components
#year
nyc_train_data$pickup_year <- year(nyc_train_data$pickup_datetime)
#month
nyc_train_data$pickup_month <- month(nyc_train_data$pickup_datetime)
#date
nyc_train_data$pickup_date <- day(nyc_train_data$pickup_datetime)
#hour
nyc_train_data$pickup_hour <- hour(nyc_train_data$pickup_datetime)
#day of week - 1 - Sunday to 7- Saturday
nyc_train_data$pickup_dow <- wday(nyc_train_data$pickup_datetime)



#TEST DATA - date-time components
#year
nyc_test_data$pickup_year <- year(nyc_test_data$pickup_datetime)
#month
nyc_test_data$pickup_month <- month(nyc_test_data$pickup_datetime)
#date
nyc_test_data$pickup_date <- day(nyc_test_data$pickup_datetime)
#hour
nyc_test_data$pickup_hour <- hour(nyc_test_data$pickup_datetime)
#day of week
nyc_test_data$pickup_dow <- wday(nyc_test_data$pickup_datetime)

```


```{r}
class(nyc_train_data$pickup_datetime)
```


```{r}
head(nyc_train_data)
head(nyc_test_data)
```


#Q3. Does number of passengers affect the fare?
```{r}
hist(nyc_train_data$passenger_count,xlab="Number of Passengers",main="Impact of Passenger count on fare amount", col="orange", border="black")

```

```{r}
plot(x= nyc_train_data$passenger_count, y= nyc_train_data$fare_amount,main="Scatter Plot Passenger count vs Fare amount", xlab="Number of Passengers", ylab="Fare Amount")
```

Based on above plot, we can deduce that single passengers have higher frequency of travelling and also contribute towards the highest fare amount for cab rides.


#Q1. Does pick up date and time affect the fare?
```{r}
plot(x= nyc_train_data$pickup_date, y= nyc_train_data$fare_amount,main="Scatter Plot Pickup Date vs Fare amount", xlab="Pick up Date", ylab="Fare Amount")
```

The fare amount throughout the month remain uniform with the highest fare captured on date 12.


```{r}
hist(nyc_train_data$pickup_hour,xlab="Pick up Hour",main="Impact of Pickup Hour on fare amount", col="orange", border="black", breaks=100)
```

We can see that the time of te days plays an crucial role. The frequency is lower at 5 AM and highest at 7 PM.

```{r}
plot(x= nyc_train_data$pickup_hour, y= nyc_train_data$fare_amount,main="Scatter Plot Pickup Hour vs Fare amount", xlab="Pick up Hour", ylab="Fare Amount")
```

Still the fares seems to be higher between 5AM TO 10 AM , 2 PM to 4 PM.This might be due to people living far prefer to leave early to avoid traffic.


#Q2. Does day of the week affect the fare?
```{r}
hist(nyc_train_data$pickup_dow,xlab="Day of the week",main="Impact of Days of week on fare amount", col="orange", border="black", breaks=100)
```

We can observe a similar behvior on all the days of the week.

```{r}
plot(x= nyc_train_data$pickup_dow, y= nyc_train_data$fare_amount,main="Scatter Plot Day of Week vs Fare amount", xlab="Pick up Day of Week", ylab="Fare Amount")
```


#We can observe that highest fares are incurred on Sunday and Monday  and lowest on Wednesday and Friday.  Perhaps people make longer trips (to visit relatives or friends) on Sundays and return on Monday. After a busy workweek, spend Friday at home.



#--------------------------------------TIME SERIES FORECASTING-----------------------------------------------------

TIME SERIES  - 

```{r}
summary(nyc_train_data)
```

```{r}
str(nyc_train_data)
```


#TRANSFOMRING DATASET INTO YEAR-MONTH DATA - SUM(FARE_AMOUNT GROUP BY MONTH)
```{r}
ym_data <- nyc_train_data   #creating copy of cleaned dataset

ym_data$month <- month(ym_data$key) #month column 
ym_data$date_ym <- floor_date(ym_data$key,"month" )  #from key, extract month column
```


```{r}
#aggregate using lubdridate and dplyr 
ym_data <- ym_data %>% 
  group_by(date_ym) %>% 
  dplyr::summarize(fare_amount = sum(fare_amount)) %>%
  as.data.frame()
```

```{r}
#TAKE LOG OF FARE AMOUNTS FOR TIME SERIES PURPOSE(scaling down)
ym_data$log_fare_amount <- log(ym_data$fare_amount)
```


#GROUP BY HOUR 
```{r}
hr_data <- nyc_train_data   #creating copy of cleaned dataset

hr_data$hour <- hour(hr_data$key) #month column 
hr_data$date_hr <- floor_date(hr_data$key,"hour" )  #from key, extract month column

hr_data <- hr_data %>% 
  group_by(date_hr) %>% 
  dplyr::summarize(fare_amount = sum(fare_amount)) %>%
  as.data.frame()
```



Converting the dataset to a time series object
```{r}
#year - month ts
ts_train <- ts(ym_data$log_fare_amount, start =c(2009,01,01), frequency = 12)

#hourly ts
ts_train_hr <- ts(hr_data$fare_amount, start =c(2009,01,01), end=c(2015,06,30), frequency = 60)


```


```{r}
print(ts_train)
```

```{r}
print(ts_train_hr)
```


Decompose Time series Train data  - year month
```{r}
components.ts = decompose(ts_train)
plot(components.ts)
```

Hourly decomposition
```{r}
components.ts_hr = decompose(ts_train_hr)
plot(components.ts_hr)
```



```{r}
p <- ggplot(ym_data, aes(x=date_ym, y=fare_amount)) +
  geom_line( color="steelblue") + 
  geom_point() +
  xlab("Year") +
  ylab("Fare amount")+
  theme_ipsum() +
  theme(axis.text.x=element_text(angle=60, hjust=1)) 
p
```

Points to note before proceeding to Time Series Forecasting

Based on above graph we can deduce two things,

1. A clear picture of upward trend can be seen in the data (fare amount)
2. Over time, the variabilty in the data is increasing

We need to remove both these patterns to stationarize our time series

As the data shows changing variance over time, we take the log transform and the resulting series will be a linear ime series. Hence we take log() of fare amount and store it as a column in ym_data dataframe.

Now let's graphically represent the log tranformed time series and check variablity.

```{r}
p_2 <- ggplot(ym_data, aes(x=date_ym, y=log(fare_amount))) +
  geom_line( color="steelblue") + 
  geom_point() +
  xlab("Year") +
  ylab("Fare amount")+
  theme_ipsum() +
  theme(axis.text.x=element_text(angle=60, hjust=1)) 
p_2
```

Clealry, the variablity is reduced and we can proceed to remove trend in time series (mentioned in the later sections)

```{r}
plot.ts(ts_train)
```


#Stationarity - Mean is constant and Standard Deviation(Variance) is constant
```{r}
adf.test(ts_train, alternative = "stationary")
```

#ADF- Augmented Dickey Fuller Test 
Based on hypothesis test, the ADF test produces a p-value greater than significance level 5% or 0.05. Hence we accept null hypothesis and reject the alternate hypothesis that our time series is not stationary.


#Making the time series stationary by differencing first order

```{r}
#DIFFERENCING LOG SERIES
plot.ts(diff(ts_train, differences = 12))
```

```{r}
adf.test(diff(ts_train, differences = 12), alternative = "stationary")
```

Now, based on the adf test and above graph a difference of first order yeilds that the null hypothesis can be rejected and we can accept the alternate hypothesis that the time series is stationary.

#----------------- ACF and PACF PLOTS ----------------------------------------------------------

#Auto correlation and Partial Auto correlarion funtions to determine p and q values in ARIMA 
Next we move on to ACF and PACF plots

Taking 12th differnces (seasonal difference)
And 1 lag - acf(diff())
```{r}
acf(diff(ts_train, differences = 12))
```



```{r}
pacf(diff(ts_train, differences = 12))
```



#-----------------------AR MODEL -------------------
p : pacf() function - AR model
d : degree of differencing
q : acf() function - MA model

```{r}

ar_model <- arima(ts_train, order = c(1,1,0))

ar_model
```

```{r}
coeftest(ar_model)
```

AR model with p=1,d=1 and q=0 yields Log Likelihood of 85.18 and AIC score of -166.35



#-----------------------MA MODEL -------------------
```{r}
ma_model <- arima(ts_train, order = c(0,1,1))
ma_model
```

```{r}
coeftest(ma_model)
```

MA model with p=0,d=1 and q=1 yields Log Likelihood of 88.4 and AIC score of -172.79


#----------------------- ARIMA MODEL -------------------

```{r}
arima_model_1 <- arima(ts_train, order = c(1,1,1))
arima_model_1
```


```{r}
coeftest(arima_model_1)
```


ARIMA model with p=0,d=1 and q=1 yields Log Likelihood of 92.84 and AIC score of -179.68

We can increase the order of lag in ARIMA with p=2 and q=2

```{r}
arima_model_2 <- arima(ts_train, order = c(2,1,2))
arima_model_2

coeftest(arima_model_2)
```

ARIMA model with p=2,d=1 and q=2 yields Log Likelihood of 99.1 and AIC score of -188.2



#----------------------- AUTO ARIMA MODEL -------------------

```{r}
auto_arima_model <- auto.arima(ts_train, trace = TRUE)
auto_arima_model
```

```{r}
best_arima <- arima(ts_train, order = c(0,1,2), seasonal = list(order=c(2,1,1), period=12))
best_arima
coeftest(best_arima)
```




#---------------- FORECASTIN FARE AMOUNT BY MONTH --------------------------
```{r}
#SPLIT THE ORIGINAL TRAIN SET INTO TRAIN_FR AND TEST_FR SETS

ts_train_partition <- ts_split(ts_train, sample.out = 12) #train 2009-01 to 2014-05 and test 2014-06 to 2015-06
train_fr <- ts_train_partition$train
test_fr <- ts_train_partition$test

length(train_fr)
length(test_fr)
``` 

#FORECAST AND PREDICT
```{r}
#train values
history_train <- copy(train_fr)

#as.array(history_train)

#list to store predictons
preds <- list()

ts_model <- arima(history_train, order = c(2,1,2))
output <- forecast(ts_model)

train_res = rmse(as.numeric(history_train), as.numeric(output[["fitted"]]))
cat("Train RMSE:", train_res)


#predicting test values
preds <- predict(ts_model,n.ahead = 12)

test_res = rmse(as.numeric(test_fr), as.numeric(preds[["pred"]]))
cat("\nTest RMSE:", test_res)

```

```{r}
train_mape = mape(as.numeric(history_train), as.numeric(output[["fitted"]]))

test_mape = mape(as.numeric(test_fr), as.numeric(preds[["pred"]]))

cat("Train MAPE: ",train_mape)
cat("\n Test MAPE: ",test_mape)
```


#BEST MODEL - based on auto arima results - predictions - SEASONAL ARIMA
```{r}
bm_history_train <- copy(train_fr)

#as.array(history_train)

bm_ts_model <- arima(bm_history_train, order = c(0,1,2), seasonal = list(order=c(2,1,1), period=12)) #period 4 , 12 months
bm_output <- forecast(bm_ts_model)

bm_train_res = rmse(as.numeric(bm_history_train), as.numeric(bm_output[["fitted"]]))
cat("Best Model Train RMSE:", bm_train_res)


#predicting test values
bm_preds <- predict(bm_ts_model,n.ahead = 12)

bm_test_res = rmse(as.numeric(test_fr), as.numeric(bm_preds[["pred"]]))
cat("\nBest Model Test RMSE:", bm_test_res)
```

```{r}
bm_train_mape = mape(as.numeric(bm_history_train), as.numeric(bm_output[["fitted"]]))

bm_test_mape = mape(as.numeric(test_fr), as.numeric(bm_preds[["pred"]]))

cat("Best model Train MAPE: ",bm_train_mape)
cat("\n Best model Test MAPE: ",bm_test_mape)
```


```{r}
cat(as.numeric(test_fr))
cat(as.numeric(output[["fitted"]]))
```

#PLOTS FOR TRAIN FORECASTS
```{r}
autoplot(output, ylab="Log Differenced Montly fare amount")
```

```{r}
plot(1:66, train_fr, xlim = c(0, 80), ylim=c(12, 13), ylab = "Log of Montly fare amount")
lines(1:66, train_fr, type="l" )
lines(1:66, output$fitted, type="l", col="red")
```
#test preds
```{r}
plot(1:12, test_fr, xlim = c(0, 20), ylim=c(12, 13), ylab = "Log of Montly fare amount")
lines(1:12, test_fr, type="l" )
lines(1:12, preds$pred, type="l", col="red")
```


#BEST MODEL - SARIMA
```{r}
autoplot(bm_output,ylab="Log Differenced Montly fare amount")
```

```{r}
plot(1:66, train_fr, xlim = c(0, 80), ylim=c(12, 13), ylab = "Log of Montly fare amount")
lines(1:66, train_fr, type="l" )
lines(1:66, bm_output$fitted, type="l", col="red")
```

```{r}
plot(1:12, test_fr, xlim = c(0, 20), ylim=c(12, 13), ylab = "Log of Montly fare amount")
lines(1:12, test_fr, type="l" )
lines(1:12, bm_preds$pred, type="l", col="red")
```

#TS.PLOT FOR ARIMA AND BETS MODEL SARIMA
#arima - train and test preds in dotted line
```{r}
ts.plot(train_fr,preds$pred,log ="y", lty=c(1,3))
```

#best model sarima - train and test preds in dotted line
```{r}
ts.plot(train_fr,bm_preds$pred,log ="y", lty=c(1,3))
```



#------------------------------ HOURLY DATA RIME SERIES MODEL ------------------------
```{r}
plot.ts(ts_train_hr)
```

Variance needs to be adjsuted - Taking Log transform 
```{r}
plot.ts(log(ts_train_hr))
```

ADF TEST FOR HOURLY DATA
```{r}
adf.test(diff(log(ts_train_hr), differences = 7), alternative = "stationary")
```

#ACF and PACF PLOTS
Taking 7th differences (seasonal difference)
And 1 lag - acf(diff())
```{r}
acf(diff(log(ts_train_hr), differences = 7))
```

```{r}
pacf(diff(log(ts_train_hr), differences = 7))
```

#ARIMA MODEL FOR HOURLY DATA
p -  pacf() AR  component - 4
d - 1 difference
q - acf() MA component - 4
```{r}
arima_model_hr_1 <- arima(log(ts_train_hr), order = c(1,0,1))
arima_model_hr_1
```

```{r}
coeftest(arima_model_hr_1)
```


#AUTO ARIMA FOR HOURLY DATA
```{r}
auto_arima_model_hr <- auto.arima(log(ts_train_hr), trace = TRUE)
auto_arima_model_hr
```

```{r}
library(lmtest)
```


```{r}
best_arima_hr <- arima(log(ts_train_hr), order = c(2,0,1), seasonal = list(order=c(2,0,0), period=60))
best_arima_hr
coeftest(best_arima_hr)
```


#FORECASTING BY HOUR
```{r}
#SPLIT THE ORIGINAL TRAIN SET INTO TRAIN_FR AND TEST_FR SETS

ts_train_partition_hr <- ts_split(log(ts_train_hr), sample.out = 55) #train ABOUT 85% - 15% test split time series
train_fr_hr <- ts_train_partition_hr$train
test_fr_hr <- ts_train_partition_hr$test

length(train_fr_hr)
length(test_fr_hr)
```

```{r}
bm_history_train_hr <- copy(train_fr_hr)


bm_ts_model_hr <- arima(bm_history_train_hr, order = c(2,0,1), seasonal = list(order=c(2,0,1), period=60)) #60 mins 

bm_output_hr <- forecast(bm_ts_model_hr)

bm_train_res_hr = rmse(as.numeric(bm_history_train_hr), as.numeric(bm_output_hr[["fitted"]]))
cat("Best Model Train RMSE:", bm_train_res_hr)


#predicting test values
bm_preds_hr <- predict(bm_ts_model_hr,n.ahead = 55)

bm_test_res_hr = rmse(as.numeric(test_fr_hr), as.numeric(bm_preds_hr[["pred"]]))
cat("\nBest Model Test RMSE:", bm_test_res_hr)
```

```{r}

bm_train_mape_hr = mape(as.numeric(bm_history_train_hr), as.numeric(bm_output_hr[["fitted"]]))

bm_test_mape_hr = mape(as.numeric(test_fr_hr), as.numeric(bm_preds_hr[["pred"]]))

cat("Best Model Hourly data Train MAPE:", bm_train_mape_hr)
cat("\nBest Model Hourly Test MAPE:", bm_test_mape_hr)
```


```{r}
plot(1:311, train_fr_hr, xlim = c(0, 320), ylim=c(2, 7), ylab = "Log of Hourly fare amount")
lines(1:311, train_fr_hr, type="l" )
lines(1:311, bm_output_hr$fitted, type="l", col="red")
```

```{r}
plot(1:55, test_fr_hr, xlim = c(0, 60), ylim=c(2, 7), ylab = "Log of Hourly fare amount")
lines(1:55, test_fr_hr, type="l" )
lines(1:55, bm_preds_hr$pred, type="l", col="red")
```


```{r}
autoplot(bm_output_hr,ylab="Log Hourly fare amount")
```


